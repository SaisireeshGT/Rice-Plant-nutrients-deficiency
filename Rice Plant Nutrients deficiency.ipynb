{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1891018,"sourceType":"datasetVersion","datasetId":1126682}],"dockerImageVersionId":30527,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nfrom tensorflow.keras import models, layers\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nimport cv2\nimport numpy as np\nimport os\nimport PIL\nfrom tensorflow.keras.utils import to_categorical\nfrom pathlib import Path\nimport zipfile\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy.stats import mode","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:04:33.925751Z","iopub.execute_input":"2024-02-04T05:04:33.926020Z","iopub.status.idle":"2024-02-04T05:04:44.067794Z","shell.execute_reply.started":"2024-02-04T05:04:33.925995Z","shell.execute_reply":"2024-02-04T05:04:44.066714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame(columns=['directory', 'label'])\n\nfor i in os.listdir('../input/nutrientdeficiencysymptomsinrice/rice_plant_lacks_nutrients'):\n    for j in os.listdir('../input/nutrientdeficiencysymptomsinrice/rice_plant_lacks_nutrients' + '/' + i + '/'):\n        train_df = pd.concat([train_df, pd.DataFrame({'directory': ['../input/nutrientdeficiencysymptomsinrice/rice_plant_lacks_nutrients' + '/' + i + '/' + j],\n                                                     'label': [i]})], ignore_index=True)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names={\n             'NITROGEN':0,\n             'PHOSPHORUS':1,\n             'POTASSIUM':2\n             }","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(train_df['label'])\ntrain_df['label_encoded'] = label_encoder.transform(train_df['label'])","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.drop(columns=['label'], inplace=True) ","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_list = []\nlabel_list = []\nfor i in range(len(train_df)):\n    image = cv2.imread(train_df['directory'][i])\n    image = cv2.resize(image,(256,1280))\n    image_list.append(image)\n    label_list.append(train_df['label_encoded'][i])\n\nimage_list = np.array(image_list)\nlabel_list = np.array(label_list)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = image_list[:1100]  \ntest_x = image_list[1100:] \ntrain_y = label_list[:1100]  \ntest_y = label_list[1100:]","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_parts = 5\nnew_height = train_x[0].shape[0] // num_parts\nx_train_parts = [image[i:i+new_height, :] for image in train_x for i in range(0, train_x[0].shape[0], new_height)]\ny_train_parts = []\nfor i in range(len(train_x)):\n    y_train_parts.extend([train_y[i]] * num_parts)\ny_train_parts = np.array(y_train_parts)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [0, 1, 2]\nencoded_labels = to_categorical(y_train_parts, num_classes=3)\nprint(encoded_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes=3\nx_train_parts=np.array(x_train_parts)\ny_train_encoded = tf.one_hot(y_train_parts, depth=num_classes, dtype=tf.float32)\ny_train_encoded = np.array(y_train_encoded) \nx_train_parts = x_train_parts.astype('float32')\nx_train_parts = x_train_parts/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_parts","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_parts.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_labels.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame(columns=['directory', 'label'])\nfor i in os.listdir('../input/nutrientdeficiencysymptomsinrice/rice_plant_lacks_nutrients'):\n    for j in os.listdir('../input/nutrientdeficiencysymptomsinrice/rice_plant_lacks_nutrients' + '/' + i + '/'):\n        train_df = pd.concat([train_df, pd.DataFrame({'directory': ['../input/nutrientdeficiencysymptomsinrice/rice_plant_lacks_nutrients' + '/' + i + '/' + j],\n                                                      'label': [i]})], ignore_index=True)\n\nlabel_encoder = LabelEncoder()\ntrain_df['label_encoded'] = label_encoder.fit_transform(train_df['label'])\ntrain_df.drop(columns=['label'], inplace=True)\nimage_list = [cv2.resize(cv2.imread(directory), (256, 1280)) for directory in train_df['directory']]\nnum_parts = 5\nnew_width = 256\nnew_height = 256\nx_train_parts = []\ny_train_parts = []\n\nfor image in image_list:\n    for i in range(0, image.shape[1], new_width):\n        for j in range(0, image.shape[0], new_height):\n            x_train_parts.append(image[j:j+new_height, i:i+new_width])\nx_train_parts = np.array(x_train_parts)\ny_train_parts = np.repeat(train_df['label_encoded'], num_parts)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:04:59.370333Z","iopub.execute_input":"2024-02-04T05:04:59.371367Z","iopub.status.idle":"2024-02-04T05:05:49.552094Z","shell.execute_reply.started":"2024-02-04T05:04:59.371327Z","shell.execute_reply":"2024-02-04T05:05:49.551267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_parts = x_train_parts.astype('float32') / 255\nencoded_labels = to_categorical(y_train_parts, num_classes=3)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:05:57.125717Z","iopub.execute_input":"2024-02-04T05:05:57.126379Z","iopub.status.idle":"2024-02-04T05:05:58.631993Z","shell.execute_reply.started":"2024-02-04T05:05:57.126342Z","shell.execute_reply":"2024-02-04T05:05:58.630889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:06:23.695152Z","iopub.execute_input":"2024-02-04T05:06:23.695537Z","iopub.status.idle":"2024-02-04T05:06:23.700085Z","shell.execute_reply.started":"2024-02-04T05:06:23.695496Z","shell.execute_reply":"2024-02-04T05:06:23.699023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x_train_parts, y_train_parts, test_size=0.1, random_state=42)\nencoded_labels_train = to_categorical(y_train, num_classes=3)\nencoded_labels_val = to_categorical(y_val, num_classes=3)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:06:26.804780Z","iopub.execute_input":"2024-02-04T05:06:26.805497Z","iopub.status.idle":"2024-02-04T05:06:28.087758Z","shell.execute_reply.started":"2024-02-04T05:06:26.805456Z","shell.execute_reply":"2024-02-04T05:06:28.086891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(256, 256, 3)),\n    layers.Flatten(),\n    layers.Dense(32, activation='relu'),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(3, activation='softmax')\n])\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(x_train, encoded_labels_train, epochs=5, validation_data=(x_val, encoded_labels_val))","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:06:31.210373Z","iopub.execute_input":"2024-02-04T05:06:31.210993Z","iopub.status.idle":"2024-02-04T05:07:24.526453Z","shell.execute_reply.started":"2024-02-04T05:06:31.210960Z","shell.execute_reply":"2024-02-04T05:07:24.525450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"deciese\")","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:09:06.390163Z","iopub.execute_input":"2024-02-04T05:09:06.391129Z","iopub.status.idle":"2024-02-04T05:09:08.224462Z","shell.execute_reply.started":"2024-02-04T05:09:06.391079Z","shell.execute_reply":"2024-02-04T05:09:08.223491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:08:43.110186Z","iopub.execute_input":"2024-02-04T05:08:43.111088Z","iopub.status.idle":"2024-02-04T05:08:43.115253Z","shell.execute_reply.started":"2024-02-04T05:08:43.111052Z","shell.execute_reply":"2024-02-04T05:08:43.114306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"loaded_model = load_model('/kaggle/working/deciese')","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:09:11.125041Z","iopub.execute_input":"2024-02-04T05:09:11.125785Z","iopub.status.idle":"2024-02-04T05:09:11.818824Z","shell.execute_reply.started":"2024-02-04T05:09:11.125747Z","shell.execute_reply":"2024-02-04T05:09:11.817787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_labels_train = to_categorical(y_train, num_classes=3)\nencoded_labels_val = to_categorical(y_val, num_classes=3)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:09:15.485197Z","iopub.execute_input":"2024-02-04T05:09:15.486035Z","iopub.status.idle":"2024-02-04T05:09:15.490886Z","shell.execute_reply.started":"2024-02-04T05:09:15.485999Z","shell.execute_reply":"2024-02-04T05:09:15.490002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = loaded_model.evaluate(x_val, encoded_labels_val)\nprint(f'Test Loss: {loss:.4f}')\nprint(f'Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:09:21.830222Z","iopub.execute_input":"2024-02-04T05:09:21.831055Z","iopub.status.idle":"2024-02-04T05:09:23.303052Z","shell.execute_reply.started":"2024-02-04T05:09:21.831019Z","shell.execute_reply":"2024-02-04T05:09:23.302014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_list=np.array(image_list)\nimage_list[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:22:40.560215Z","iopub.execute_input":"2024-02-04T05:22:40.561285Z","iopub.status.idle":"2024-02-04T05:22:40.897454Z","shell.execute_reply.started":"2024-02-04T05:22:40.561242Z","shell.execute_reply":"2024-02-04T05:22:40.896451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_labels_train = to_categorical(y_train, num_classes=3)\nencoded_labels_val = to_categorical(y_val, num_classes=3)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:09:37.365397Z","iopub.execute_input":"2024-02-04T05:09:37.366279Z","iopub.status.idle":"2024-02-04T05:09:37.371208Z","shell.execute_reply.started":"2024-02-04T05:09:37.366244Z","shell.execute_reply":"2024-02-04T05:09:37.370263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\noriginal_labels = ['NITROGEN', 'PHOSPHORUS', 'POTASSIUM']  # Replace with your actual class labels\nlabel_encoder.fit(original_labels)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:09:40.625093Z","iopub.execute_input":"2024-02-04T05:09:40.625941Z","iopub.status.idle":"2024-02-04T05:09:40.641941Z","shell.execute_reply.started":"2024-02-04T05:09:40.625904Z","shell.execute_reply":"2024-02-04T05:09:40.639204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_list[150].shape","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:21:19.709685Z","iopub.execute_input":"2024-02-04T05:21:19.710047Z","iopub.status.idle":"2024-02-04T05:21:19.716134Z","shell.execute_reply.started":"2024-02-04T05:21:19.710018Z","shell.execute_reply":"2024-02-04T05:21:19.715152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_parts = 5\nnew_width = 256\nnew_height = 256\nimage_parts = []\nsingle_image=image_list[150]\nfor i in range(0, single_image.shape[1], new_width):\n    for j in range(0, single_image.shape[0], new_height):\n        image_parts.append(single_image[j:j+new_height, i:i+new_width])\n\n# Convert the list of image parts to a NumPy array\nimage_parts = np.array(image_parts)\n\n# Normalize pixel values\nimage_parts = image_parts.astype('float32') / 255\n\n# Reshape the image parts array to match the input shape expected by the model\nimage_parts = image_parts.reshape((-1, 256, 256, 3))\npredictions = loaded_model.predict(image_parts)\n\n# Get the class with the highest probability for each part\npredicted_classes = np.argmax(predictions, axis=1)\npredicted_probabilities = np.max(predictions, axis=1)\npredicted_labels = label_encoder.inverse_transform(predicted_classes)\n\nmajority_class, _ = mode(predicted_labels)\naverage_probability = np.mean(predicted_probabilities)\nprint(f\"Combined Predicted Label (Majority Class): {majority_class[0]}\")\nprint(f\"Combined Predicted Probability (Average): {average_probability:.4f}\")\nplt.imshow(single_image)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:09:47.299895Z","iopub.execute_input":"2024-02-04T05:09:47.300277Z","iopub.status.idle":"2024-02-04T05:09:47.844822Z","shell.execute_reply.started":"2024-02-04T05:09:47.300247Z","shell.execute_reply":"2024-02-04T05:09:47.843896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the following bellow code can not work in kaggle notebook\nfrom flask import Flask, render_template_string, request\nimport cv2\nimport numpy as np\nfrom scipy.stats import mode\nfrom sklearn.preprocessing import LabelEncoder\n\napp = Flask(__name__)\n\n# Define label encoder\noriginal_labels = ['NITROGEN', 'PHOSPHORUS', 'POTASSIUM']\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(original_labels)\n\n@app.route('/', methods=['GET', 'POST'])\ndef predict():\n    prediction_result = None\n    selected_image = None\n\n    if request.method == 'POST':\n        # Get the file from the POST request\n        file = request.files['file']\n\n        # Read the image\n        image = cv2.imdecode(np.fromstring(file.read(), np.uint8), cv2.IMREAD_COLOR)\n        image = cv2.resize(image, (256, 1280))\n\n        num_parts = 5\n        new_width = 256\n        new_height = 256\n        image_parts = []\n        for i in range(0, image.shape[1], new_width):\n            for j in range(0, image.shape[0], new_height):\n                image_parts.append(image[j:j+new_height, i:i+new_width])\n\n        # Convert the list of image parts to a NumPy array\n        image_parts = np.array(image_parts)\n\n        # Normalize pixel values\n        image_parts = image_parts.astype('float32') / 255\n\n        # Reshape the image parts array to match the input shape expected by the model\n        image_parts = image_parts.reshape((-1, 256, 256, 3))\n\n        # Assuming you have loaded your pre-trained model as 'loaded_model'\n        # Load your model here\n\n        # Make predictions\n        predictions = loaded_model.predict(image_parts)\n\n        # Get the class with the highest probability for each part\n        predicted_classes = np.argmax(predictions, axis=1)\n        predicted_labels = [label_mapping[p] for p in predicted_classes]\n\n        # Calculate the average probability\n        average_probability = np.mean(np.max(predictions, axis=1))\n        unique_labels, counts = np.unique(predicted_labels, return_counts=True)\n        max_count_index = np.argmax(counts)\n        majority_class = unique_labels[max_count_index]\n        prediction_result = f\"Combined Predicted Label (Majority Class): {majority_class}, Combined Predicted Probability (Average): {average_probability:.4f}\"\n\n        # Convert the selected image to base64 encoding\n        _, buffer = cv2.imencode('.jpg', image)\n        image_encoded = base64.b64encode(buffer).decode('utf-8')\n        selected_image = f\"data:image/jpeg;base64,{image_encoded}\"\n         return render_template_string('''\n        <!DOCTYPE html>\n        <html lang=\"en\">\n        <head>\n            <meta charset=\"UTF-8\">\n            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n            <title>Upload Image</title>\n            <style>\n       \n            display: flex;\n            justify-content: center;\n            align-items: center;\n            height: 100vh; /* Set height to viewport height for vertical centering */\n            margin: 0; /* Remove default margin */\n            padding: 0; /* Remove default padding */\n        }\n        .content {\n            text-align: center;\n        }\n    </style>\n        </head>\n        <body>\n            <h1>Upload an Image</h1>\n            <form method=\"post\" enctype=\"multipart/form-data\">\n                <input type=\"file\" name=\"file\" accept=\"image/*\">\n                <input type=\"submit\" value=\"Upload\">\n            </form>\n            {% if selected_image %}\n            <div>\n                <h2>Selected Image</h2>\n                <img src=\"{{ selected_image }}\" alt=\"Selected Image\">\n            </div>\n            {% endif %}\n            {% if prediction_result %}\n            <div>\n                <h2>Prediction Result</h2>\n                <p>{{ prediction_result }}</p>\n            </div>\n            {% endif %}\n        </body>\n        </html>\n    ''', prediction_result=prediction_result, selected_image=selected_image)\n\nif __name__ == '__main__':\n    app.run(debug=False, use_reloader=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T17:07:54.038369Z","iopub.execute_input":"2024-02-03T17:07:54.039305Z","iopub.status.idle":"2024-02-03T17:08:20.782084Z","shell.execute_reply.started":"2024-02-03T17:07:54.039271Z","shell.execute_reply":"2024-02-03T17:08:20.780572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-02-04T05:36:03.844722Z","iopub.execute_input":"2024-02-04T05:36:03.845394Z","iopub.status.idle":"2024-02-04T05:36:03.851159Z","shell.execute_reply.started":"2024-02-04T05:36:03.845359Z","shell.execute_reply":"2024-02-04T05:36:03.850302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-02-03T13:44:23.708730Z","iopub.execute_input":"2024-02-03T13:44:23.709141Z","iopub.status.idle":"2024-02-03T13:44:24.709328Z","shell.execute_reply.started":"2024-02-03T13:44:23.709103Z","shell.execute_reply":"2024-02-03T13:44:24.707909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}